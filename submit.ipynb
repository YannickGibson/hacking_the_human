{"cells":[{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:00.717222Z","iopub.status.busy":"2023-07-31T16:47:00.716920Z","iopub.status.idle":"2023-07-31T16:47:00.730587Z","shell.execute_reply":"2023-07-31T16:47:00.729405Z","shell.execute_reply.started":"2023-07-31T16:47:00.717197Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Work started\n"]}],"source":["print(\"Work started\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:00.732399Z","iopub.status.busy":"2023-07-31T16:47:00.732095Z","iopub.status.idle":"2023-07-31T16:47:07.711250Z","shell.execute_reply":"2023-07-31T16:47:07.710156Z","shell.execute_reply.started":"2023-07-31T16:47:00.732373Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -q --no-index --no-deps /kaggle/input/pycocotools-206/wheels/*.whl\n","from pycocotools import _mask as coco_mask\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:07.713460Z","iopub.status.busy":"2023-07-31T16:47:07.712736Z","iopub.status.idle":"2023-07-31T16:47:32.826509Z","shell.execute_reply":"2023-07-31T16:47:32.825017Z","shell.execute_reply.started":"2023-07-31T16:47:07.713424Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33m    WARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: Cannot uninstall typing-extensions 4.5.0, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps typing-extensions==4.5.0'.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q --no-index --no-deps /kaggle/input/myupload/*.whl\n","import segmentation_models_pytorch\n","from segmentation_models_pytorch.encoders import get_preprocessing_fn"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.828659Z","iopub.status.busy":"2023-07-31T16:47:32.828289Z","iopub.status.idle":"2023-07-31T16:47:32.833996Z","shell.execute_reply":"2023-07-31T16:47:32.832916Z","shell.execute_reply.started":"2023-07-31T16:47:32.828625Z"},"trusted":true},"outputs":[],"source":["#from IPython.display import FileLink\n","#FileLink(r'segmentation_models_pytorch.zip')"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.836546Z","iopub.status.busy":"2023-07-31T16:47:32.835745Z","iopub.status.idle":"2023-07-31T16:47:32.851528Z","shell.execute_reply":"2023-07-31T16:47:32.850717Z","shell.execute_reply.started":"2023-07-31T16:47:32.836512Z"},"trusted":true},"outputs":[],"source":["#!pip install pycocotools==2.0.6\n","#!pip install segmentation_models_pytorch\n","import numpy as np\n","from typing import Text\n","import base64\n","import numpy as np\n","import pandas as pd\n","import zlib\n","import glob\n","import os\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import tifffile\n","\n","\n","import torch\n","import torch.nn as nn\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.854083Z","iopub.status.busy":"2023-07-31T16:47:32.853245Z","iopub.status.idle":"2023-07-31T16:47:32.863686Z","shell.execute_reply":"2023-07-31T16:47:32.862951Z","shell.execute_reply.started":"2023-07-31T16:47:32.854042Z"},"trusted":true},"outputs":[],"source":["def encode_binary_mask(mask: np.ndarray) -> Text:\n","  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n","\n","  # check input mask --\n","  if mask.dtype != bool:\n","    raise ValueError(\n","        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n","        mask.dtype)\n","\n","  mask = np.squeeze(mask)\n","  if len(mask.shape) != 2:\n","    raise ValueError(\n","        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n","        mask.shape)\n","\n","  # convert input mask to expected COCO API input --\n","  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n","  mask_to_encode = mask_to_encode.astype(np.uint8)\n","  mask_to_encode = np.asfortranarray(mask_to_encode)\n","\n","  # RLE encode mask --\n","  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n","\n","  # compress and base64 encoding --\n","  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n","  base64_str = base64.b64encode(binary_str)\n","  return base64_str"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.865680Z","iopub.status.busy":"2023-07-31T16:47:32.865273Z","iopub.status.idle":"2023-07-31T16:47:32.875710Z","shell.execute_reply":"2023-07-31T16:47:32.874890Z","shell.execute_reply.started":"2023-07-31T16:47:32.865643Z"},"trusted":true},"outputs":[],"source":["data_directory = \"/kaggle/input/hubmap-hacking-the-human-vasculature\""]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.877782Z","iopub.status.busy":"2023-07-31T16:47:32.877089Z","iopub.status.idle":"2023-07-31T16:47:32.893180Z","shell.execute_reply":"2023-07-31T16:47:32.891910Z","shell.execute_reply.started":"2023-07-31T16:47:32.877750Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.895962Z","iopub.status.busy":"2023-07-31T16:47:32.894564Z","iopub.status.idle":"2023-07-31T16:47:32.907119Z","shell.execute_reply":"2023-07-31T16:47:32.905928Z","shell.execute_reply.started":"2023-07-31T16:47:32.895928Z"},"trusted":true},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","\n","class UNetInstanceSegmentation(nn.Module):\n","    def __init__(self, num_classes=1, num_channels=3):\n","        super(UNetInstanceSegmentation, self).__init__()\n","        self.model = smp.Unet(\n","            encoder_name=\"resnet34\",  # You can choose different encoder backbones if desired.\n","            encoder_weights=\"imagenet\",\n","            in_channels=num_channels,\n","            classes=num_classes,\n","            activation='sigmoid'\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def predict(self, x):\n","        with torch.no_grad():\n","            y_pred = self.forward(x)\n","        return (y_pred > 0.5) * 1.0\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.909004Z","iopub.status.busy":"2023-07-31T16:47:32.908663Z","iopub.status.idle":"2023-07-31T16:47:32.925873Z","shell.execute_reply":"2023-07-31T16:47:32.924841Z","shell.execute_reply.started":"2023-07-31T16:47:32.908975Z"},"trusted":true},"outputs":[],"source":["#model_path = f\"/kaggle/input/test-stuff/models/onereg_20min\"\n","\n","# model.load_state_dict(torch.load(model_path))\n","\n","#model = UNetInstanceSegmentation()\n","#model.load_state_dict(torch.load(model_path))\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.927876Z","iopub.status.busy":"2023-07-31T16:47:32.927462Z","iopub.status.idle":"2023-07-31T16:47:32.941470Z","shell.execute_reply":"2023-07-31T16:47:32.940492Z","shell.execute_reply.started":"2023-07-31T16:47:32.927811Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.943748Z","iopub.status.busy":"2023-07-31T16:47:32.943137Z","iopub.status.idle":"2023-07-31T16:47:32.949691Z","shell.execute_reply":"2023-07-31T16:47:32.948969Z","shell.execute_reply.started":"2023-07-31T16:47:32.943716Z"},"trusted":true},"outputs":[],"source":["#save_whole_model = UNetInstanceSegmentation().to(device)\n","#save_whole_model.load_state_dict(torch.load('/kaggle/input/myupload2/sleepmodel_unetinstancesegmentation_preprocessing',\n","#                                            map_location=torch.device(device)), strict=False)\n","#torch.save(save_whole_model, \"sleep_wholemodel\")"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.951862Z","iopub.status.busy":"2023-07-31T16:47:32.951198Z","iopub.status.idle":"2023-07-31T16:47:32.961361Z","shell.execute_reply":"2023-07-31T16:47:32.960594Z","shell.execute_reply.started":"2023-07-31T16:47:32.951813Z"},"trusted":true},"outputs":[],"source":["#from IPython.display import FileLink\n","#FileLink(r'sleep_wholemodel')"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:32.963196Z","iopub.status.busy":"2023-07-31T16:47:32.962685Z","iopub.status.idle":"2023-07-31T16:47:33.086482Z","shell.execute_reply":"2023-07-31T16:47:33.085329Z","shell.execute_reply.started":"2023-07-31T16:47:32.963165Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class '__main__.UNetInstanceSegmentation'>\n"]}],"source":["model = torch.load(\"/kaggle/input/myupload3/sleep_wholemodel\", map_location=torch.device(device))\n","#model = torch.load(\"/kaggle/input/test-stuff/models/onereg_20min\")\n","\n","print(type(model))"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:33.088855Z","iopub.status.busy":"2023-07-31T16:47:33.088155Z","iopub.status.idle":"2023-07-31T16:47:33.095999Z","shell.execute_reply":"2023-07-31T16:47:33.094775Z","shell.execute_reply.started":"2023-07-31T16:47:33.088794Z"},"trusted":true},"outputs":[],"source":["def convert_multiple_masks(masks: list[np.ndarray], confidence_values: list[int]) -> Text:\n","    strings = []\n","    for mask, confidence in zip(masks, confidence_values):\n","        strings.append(f\"0 {confidence:.1f} {encode_binary_mask(mask).decode('utf-8')}\")\n","\n","    return ' '.join(strings)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:33.098704Z","iopub.status.busy":"2023-07-31T16:47:33.098373Z","iopub.status.idle":"2023-07-31T16:47:33.107949Z","shell.execute_reply":"2023-07-31T16:47:33.106897Z","shell.execute_reply.started":"2023-07-31T16:47:33.098677Z"},"trusted":true},"outputs":[],"source":["def instance_confidence(masks, conf_matrixes) -> list:\n","    conf_values = []\n","    for mask, conf_matrix in zip(masks, conf_matrixes):\n","        num, denom = 0, 0\n","        for i in range(mask.shape[0]):\n","            for j in range(mask.shape[1]):\n","                if mask[i][j] == 1:\n","                    num += conf_matrix[i][j]\n","                    denom += 1\n","        conf_values.append(num/denom)\n","    return conf_values"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:00.709994Z","iopub.status.busy":"2023-07-31T16:47:00.709573Z","iopub.status.idle":"2023-07-31T16:47:00.715676Z","shell.execute_reply":"2023-07-31T16:47:00.714568Z","shell.execute_reply.started":"2023-07-31T16:47:00.709947Z"},"trusted":true},"outputs":[],"source":["preprocessing_fn = get_preprocessing_fn('resnet34', pretrained='imagenet')\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:51:31.860704Z","iopub.status.busy":"2023-07-31T16:51:31.860274Z","iopub.status.idle":"2023-07-31T16:51:33.860331Z","shell.execute_reply":"2023-07-31T16:51:33.858599Z","shell.execute_reply.started":"2023-07-31T16:51:31.860672Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>height</th>\n","      <th>width</th>\n","      <th>prediction_string</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>72e40acccadf</th>\n","      <td>512</td>\n","      <td>512</td>\n","      <td>0 1.0 eNptVem2oroSfqUMRAJ791nnrt0SDBlkEhVwxBGF...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              height  width                                  prediction_string\n","id                                                                            \n","72e40acccadf     512    512  0 1.0 eNptVem2oroSfqUMRAJ791nnrt0SDBlkEhVwxBGF..."]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["submission_df = pd.DataFrame(columns=['id', 'height', 'width', 'prediction_string'])\n","\n","tif_files = glob.glob(os.path.join(f'{data_directory}/test', '*.tif'))\n","rows = []\n","for file_path in tif_files:\n","    \n","    # Preparation of image\n","    image_id = Path(file_path).stem\n","    image = tifffile.imread(file_path)\n","    height, width = image.shape[0], image.shape[1]\n","    image.resize(512, 512, 3)\n","    \n","    # Preprocessing\n","    #image = preprocessing_fn(image)\n","    image = image / 255\n","    \n","    \n","    inp = torch.tensor(image).to(device) # imread returns (512, 512, 3)\n","    inp = inp.reshape(1, 3, 512, 512) # BATCH, CHANNELS, SIZEY, SIZEX\n","    inp = inp.float() # from float64 to float32\n","\n","    # Prediction + post preparation\n","    with torch.no_grad():\n","        conf_matrix = model.forward(inp).cpu().numpy().reshape(512, 512)\n","    predicted = model.predict(inp).cpu().numpy().reshape(512, 512).astype(bool)\n","\n","    # plt.imshow(predicted.numpy().reshape(512, 512, 1), vmax=1, vmin=0, cmap=\"gray\")\n","    \n","    # Mask separation - TODO\n","    masks = []\n","    masks.append(predicted)\n","    #\n","\n","    # Confidence\n","    conf_matrixes = []\n","    conf_matrixes.append(conf_matrix)\n","\n","    # confidence =  sum of all pixels confidence over treshold divided by the number of  pixels confidence over treshold\n","    confidence_values = instance_confidence(masks, conf_matrixes)\n","    #print(confidence_values)\n","    #print(conf_matrixes)\n","\n","    # Prediction string\n","    prediction_str = convert_multiple_masks(masks, confidence_values)  \n","\n","    # Add row to list  \n","    new_row = {\n","        'id': image_id,\n","        'height': height,\n","        'width': width,\n","        'prediction_string': prediction_str\n","    }\n","    rows.append(new_row)\n","\n","\n","res = submission_df.from_dict(rows)\n","res.set_index(\"id\", inplace=True)\n","#res.reset_index(inplace=True)\n","\n","res.head()\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-07-31T16:47:35.186549Z","iopub.status.busy":"2023-07-31T16:47:35.186227Z","iopub.status.idle":"2023-07-31T16:47:35.193233Z","shell.execute_reply":"2023-07-31T16:47:35.192184Z","shell.execute_reply.started":"2023-07-31T16:47:35.186522Z"},"trusted":true},"outputs":[],"source":["#print(res)\n","res.to_csv(f'submission.csv')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
